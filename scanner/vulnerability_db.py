"""
Vulnerability Database Integration
Integrates with multiple open-source vulnerability databases for accurate threat assessment
"""

import requests
import json
import re
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import sqlite3
import os
from dataclasses import dataclass

@dataclass
class Vulnerability:
    cve_id: str
    cvss_score: float
    severity: str
    description: str
    published_date: str
    modified_date: str
    affected_products: List[str]
    references: List[str]

class VulnerabilityDatabase:
    def __init__(self):
        self.db_path = 'vulnerability_cache.db'
        self.init_database()
        
    def init_database(self):
        """Initialize local vulnerability cache database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS vulnerabilities (
                cve_id TEXT PRIMARY KEY,
                cvss_score REAL,
                severity TEXT,
                description TEXT,
                published_date TEXT,
                modified_date TEXT,
                affected_products TEXT,
                "references" TEXT,
                cached_date TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS exploit_db (
                edb_id TEXT PRIMARY KEY,
                title TEXT,
                description TEXT,
                date_published TEXT,
                author TEXT,
                type TEXT,
                platform TEXT,
                port INTEGER,
                verified BOOLEAN
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def search_cve_by_product(self, product: str, version: str = None) -> List[Vulnerability]:
        """Search CVE database for vulnerabilities affecting specific products"""
        vulnerabilities = []
        
        try:
            # NVD API search
            base_url = "https://services.nvd.nist.gov/rest/json/cves/1.0"
            params = {
                'keyword': product,
                'resultsPerPage': 50
            }
            
            if version:
                params['keyword'] += f" {version}"
            
            response = requests.get(base_url, params=params, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                for item in data.get('result', {}).get('CVE_Items', []):
                    cve_data = item.get('cve', {})
                    impact = item.get('impact', {})
                    
                    cve_id = cve_data.get('CVE_data_meta', {}).get('ID', '')
                    description = ''
                    
                    # Extract description
                    desc_data = cve_data.get('description', {}).get('description_data', [])
                    if desc_data:
                        description = desc_data[0].get('value', '')
                    
                    # Extract CVSS score
                    cvss_score = 0.0
                    severity = 'unknown'
                    
                    if 'baseMetricV3' in impact:
                        cvss_v3 = impact['baseMetricV3']['cvssV3']
                        cvss_score = cvss_v3.get('baseScore', 0.0)
                        severity = cvss_v3.get('baseSeverity', 'unknown').lower()
                    elif 'baseMetricV2' in impact:
                        cvss_v2 = impact['baseMetricV2']['cvssV2']
                        cvss_score = cvss_v2.get('baseScore', 0.0)
                        # Convert CVSS v2 score to severity
                        if cvss_score >= 7.0:
                            severity = 'high'
                        elif cvss_score >= 4.0:
                            severity = 'medium'
                        else:
                            severity = 'low'
                    
                    # Extract dates
                    published_date = item.get('publishedDate', '')
                    modified_date = item.get('lastModifiedDate', '')
                    
                    # Extract affected products
                    affected_products = []
                    configurations = item.get('configurations', {}).get('nodes', [])
                    for config in configurations:
                        for cpe_match in config.get('cpe_match', []):
                            cpe_uri = cpe_match.get('cpe23Uri', '')
                            if cpe_uri:
                                affected_products.append(cpe_uri)
                    
                    # Extract references
                    references = []
                    ref_data = cve_data.get('references', {}).get('reference_data', [])
                    for ref in ref_data:
                        references.append(ref.get('url', ''))
                    
                    vulnerability = Vulnerability(
                        cve_id=cve_id,
                        cvss_score=cvss_score,
                        severity=severity,
                        description=description,
                        published_date=published_date,
                        modified_date=modified_date,
                        affected_products=affected_products,
                        references=references
                    )
                    
                    vulnerabilities.append(vulnerability)
                    
                    # Cache in local database
                    self.cache_vulnerability(vulnerability)
            
        except Exception as e:
            print(f"Error searching CVE database: {e}")
            # Fallback to cached data
            vulnerabilities = self.search_cached_vulnerabilities(product, version)
        
        return vulnerabilities
    
    def cache_vulnerability(self, vuln: Vulnerability):
        """Cache vulnerability data locally"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO vulnerabilities 
            (cve_id, cvss_score, severity, description, published_date, 
             modified_date, affected_products, "references", cached_date)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            vuln.cve_id,
            vuln.cvss_score,
            vuln.severity,
            vuln.description,
            vuln.published_date,
            vuln.modified_date,
            json.dumps(vuln.affected_products),
            json.dumps(vuln.references),
            datetime.now().isoformat()
        ))
        
        conn.commit()
        conn.close()
    
    def search_cached_vulnerabilities(self, product: str, version: str = None) -> List[Vulnerability]:
        """Search cached vulnerability data"""
        vulnerabilities = []
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        query = '''
            SELECT * FROM vulnerabilities 
            WHERE affected_products LIKE ? OR description LIKE ?
            ORDER BY cvss_score DESC
            LIMIT 50
        '''
        
        search_term = f"%{product}%"
        cursor.execute(query, (search_term, search_term))
        
        for row in cursor.fetchall():
            vulnerability = Vulnerability(
                cve_id=row[0],
                cvss_score=row[1],
                severity=row[2],
                description=row[3],
                published_date=row[4],
                modified_date=row[5],
                affected_products=json.loads(row[6]) if row[6] else [],
                references=json.loads(row[7]) if row[7] else []
            )
            vulnerabilities.append(vulnerability)
        
        conn.close()
        return vulnerabilities
    
    def search_exploit_db(self, product: str) -> List[Dict[str, Any]]:
        """Search Exploit Database for available exploits"""
        exploits = []
        
        try:
            # Exploit-DB CSV data (would need to download and parse)
            # For now, we'll simulate with a basic search
            
            # This would integrate with the actual Exploit-DB API or CSV files
            # https://gitlab.com/exploit-database/exploitdb
            
            # Placeholder implementation
            exploits = [{
                'edb_id': 'EDB-XXXXX',
                'title': f'Exploit for {product}',
                'description': 'Placeholder exploit description',
                'date_published': datetime.now().isoformat(),
                'author': 'Security Researcher',
                'type': 'remote',
                'platform': 'multiple',
                'verified': False
            }]
            
        except Exception as e:
            print(f"Error searching Exploit-DB: {e}")
        
        return exploits
    
    def get_vulnerability_statistics(self) -> Dict[str, Any]:
        """Get vulnerability statistics from cache"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        stats = {}
        
        # Total vulnerabilities
        cursor.execute('SELECT COUNT(*) FROM vulnerabilities')
        stats['total_vulnerabilities'] = cursor.fetchone()[0]
        
        # Severity breakdown
        cursor.execute('''
            SELECT severity, COUNT(*) 
            FROM vulnerabilities 
            GROUP BY severity
        ''')
        
        severity_counts = {}
        for row in cursor.fetchall():
            severity_counts[row[0]] = row[1]
        
        stats['severity_breakdown'] = severity_counts
        
        # Recent vulnerabilities (last 30 days)
        thirty_days_ago = (datetime.now() - timedelta(days=30)).isoformat()
        cursor.execute('''
            SELECT COUNT(*) FROM vulnerabilities 
            WHERE published_date > ?
        ''', (thirty_days_ago,))
        
        stats['recent_vulnerabilities'] = cursor.fetchone()[0]
        
        # High severity vulnerabilities
        cursor.execute('''
            SELECT COUNT(*) FROM vulnerabilities 
            WHERE cvss_score >= 7.0
        ''')
        
        stats['high_severity_count'] = cursor.fetchone()[0]
        
        conn.close()
        return stats

class ThreatIntelligence:
    """Threat Intelligence integration with multiple sources"""
    
    def __init__(self):
        self.sources = {
            'alienvault_otx': 'https://otx.alienvault.com/api/v1',
            'virustotal': 'https://www.virustotal.com/vtapi/v2',
            'abuse_ch': 'https://urlhaus-api.abuse.ch/v1',
            'malware_bazaar': 'https://mb-api.abuse.ch/api/v1'
        }
    
    def check_ip_reputation(self, ip_address: str) -> Dict[str, Any]:
        """Check IP address reputation across multiple sources"""
        reputation_data = {
            'ip_address': ip_address,
            'reputation_score': 0,  # 0-100, higher is worse
            'threat_types': [],
            'sources': {}
        }
        
        try:
            # AlienVault OTX check
            otx_data = self.check_alienvault_otx_ip(ip_address)
            reputation_data['sources']['alienvault_otx'] = otx_data
            
            # Abuse.ch check
            abuse_data = self.check_abuse_ch_ip(ip_address)
            reputation_data['sources']['abuse_ch'] = abuse_data
            
            # Calculate overall reputation score
            reputation_data['reputation_score'] = self.calculate_reputation_score(
                reputation_data['sources']
            )
            
        except Exception as e:
            reputation_data['error'] = str(e)
        
        return reputation_data
    
    def check_domain_reputation(self, domain: str) -> Dict[str, Any]:
        """Check domain reputation"""
        reputation_data = {
            'domain': domain,
            'reputation_score': 0,
            'threat_types': [],
            'sources': {}
        }
        
        try:
            # Multiple source checks would go here
            reputation_data['sources']['placeholder'] = 'Domain reputation check'
            
        except Exception as e:
            reputation_data['error'] = str(e)
        
        return reputation_data
    
    def check_alienvault_otx_ip(self, ip_address: str) -> Dict[str, Any]:
        """Check IP against AlienVault OTX"""
        try:
            url = f"{self.sources['alienvault_otx']}/indicators/IPv4/{ip_address}/general"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                return response.json()
            else:
                return {'status': 'not_found'}
                
        except Exception as e:
            return {'error': str(e)}
    
    def check_abuse_ch_ip(self, ip_address: str) -> Dict[str, Any]:
        """Check IP against Abuse.ch databases"""
        try:
            # URLhaus API
            url = f"{self.sources['abuse_ch']}/host/"
            data = {'host': ip_address}
            
            response = requests.post(url, data=data, timeout=10)
            
            if response.status_code == 200:
                return response.json()
            else:
                return {'status': 'not_found'}
                
        except Exception as e:
            return {'error': str(e)}
    
    def calculate_reputation_score(self, sources_data: Dict[str, Any]) -> int:
        """Calculate overall reputation score from multiple sources"""
        score = 0
        
        # This would implement logic to combine scores from different sources
        # For now, return a placeholder score
        
        return score

class SecurityIntelligence:
    """Main class for security intelligence gathering"""
    
    def __init__(self):
        self.vuln_db = VulnerabilityDatabase()
        self.threat_intel = ThreatIntelligence()
    
    def comprehensive_threat_assessment(self, target_info: Dict[str, Any]) -> Dict[str, Any]:
        """Perform comprehensive threat assessment"""
        assessment = {
            'target': target_info,
            'timestamp': datetime.now().isoformat(),
            'vulnerabilities': [],
            'exploits': [],
            'threat_intelligence': {},
            'risk_score': 0
        }
        
        try:
            # Extract technology information
            technologies = target_info.get('technologies', {})
            
            # Search for vulnerabilities in detected technologies
            for tech_type, tech_list in technologies.items():
                if isinstance(tech_list, list):
                    for tech in tech_list:
                        vulns = self.vuln_db.search_cve_by_product(tech)
                        assessment['vulnerabilities'].extend([v.__dict__ for v in vulns])
                        
                        exploits = self.vuln_db.search_exploit_db(tech)
                        assessment['exploits'].extend(exploits)
            
            # Check IP reputation if available
            if 'ip_address' in target_info:
                ip_reputation = self.threat_intel.check_ip_reputation(target_info['ip_address'])
                assessment['threat_intelligence']['ip_reputation'] = ip_reputation
            
            # Check domain reputation
            if 'domain' in target_info:
                domain_reputation = self.threat_intel.check_domain_reputation(target_info['domain'])
                assessment['threat_intelligence']['domain_reputation'] = domain_reputation
            
            # Calculate overall risk score
            assessment['risk_score'] = self.calculate_risk_score(assessment)
            
        except Exception as e:
            assessment['error'] = str(e)
        
        return assessment
    
    def calculate_risk_score(self, assessment: Dict[str, Any]) -> int:
        """Calculate overall risk score based on assessment data"""
        base_score = 0
        
        # Add points for vulnerabilities
        for vuln in assessment.get('vulnerabilities', []):
            if isinstance(vuln, dict):
                cvss_score = vuln.get('cvss_score', 0)
                base_score += cvss_score
        
        # Add points for available exploits
        exploit_count = len(assessment.get('exploits', []))
        base_score += exploit_count * 5
        
        # Add points for threat intelligence findings
        threat_data = assessment.get('threat_intelligence', {})
        if threat_data.get('ip_reputation', {}).get('reputation_score', 0) > 50:
            base_score += 20
        
        # Normalize to 0-100 scale
        normalized_score = min(100, max(0, int(base_score)))
        
        return normalized_score
