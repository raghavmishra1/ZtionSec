"""
Enhanced Vulnerability Validation System for ZtionSec
Addresses false positives and improves detection accuracy
"""

import requests
import json
import time
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import sqlite3
import re
from urllib.parse import urlparse
import logging

logger = logging.getLogger(__name__)

@dataclass
class ValidatedVulnerability:
    """Validated vulnerability with confidence scoring"""
    cve_id: Optional[str]
    severity: str
    confidence_score: float  # 0.0 to 1.0
    category: str
    title: str
    description: str
    recommendation: str
    validation_method: str
    false_positive_likelihood: float
    references: List[str]
    affected_component: str
    proof_of_concept: str
    
class VulnerabilityValidator:
    """Enhanced vulnerability validation system"""
    
    def __init__(self):
        self.nvd_api_base = "https://services.nvd.nist.gov/rest/json/cves/2.0"
        self.validation_cache = {}
        self.false_positive_patterns = self._load_false_positive_patterns()
        self.confidence_thresholds = {
            'critical': 0.9,
            'high': 0.8,
            'medium': 0.7,
            'low': 0.6,
            'info': 0.5
        }
        
    def _load_false_positive_patterns(self) -> Dict[str, List[str]]:
        """Load known false positive patterns"""
        return {
            'ssl_issues': [
                'self-signed certificate in development',
                'localhost certificate',
                'internal testing certificate'
            ],
            'security_headers': [
                'content-security-policy in meta tag',
                'x-frame-options on non-frameable content',
                'hsts on localhost'
            ],
            'information_disclosure': [
                'server version in development environment',
                'debug information in test environment',
                'error pages with generic messages'
            ],
            'injection_vulnerabilities': [
                'sql injection in search functionality with proper escaping',
                'xss in user-generated content with sanitization',
                'command injection in sandboxed environment'
            ]
        }
    
    def validate_vulnerability(self, vulnerability_data: Dict[str, Any]) -> ValidatedVulnerability:
        """Validate a detected vulnerability and calculate confidence score"""
        
        # Extract basic information
        title = vulnerability_data.get('title', '')
        description = vulnerability_data.get('description', '')
        category = vulnerability_data.get('category', 'unknown')
        severity = vulnerability_data.get('severity', 'info')
        
        # Calculate confidence score
        confidence_score = self._calculate_confidence_score(vulnerability_data)
        
        # Check for false positive indicators
        false_positive_likelihood = self._assess_false_positive_likelihood(vulnerability_data)
        
        # Validate against external databases if CVE is provided
        cve_validation = None
        cve_id = vulnerability_data.get('cve_id')
        if cve_id:
            cve_validation = self._validate_against_nvd(cve_id)
        
        # Determine validation method
        validation_method = self._determine_validation_method(vulnerability_data, cve_validation)
        
        # Generate enhanced recommendation
        recommendation = self._generate_enhanced_recommendation(vulnerability_data, confidence_score)
        
        # Compile references
        references = vulnerability_data.get('references', [])
        if cve_validation and cve_validation.get('references'):
            references.extend(cve_validation['references'])
        
        return ValidatedVulnerability(
            cve_id=cve_id,
            severity=severity,
            confidence_score=confidence_score,
            category=category,
            title=title,
            description=description,
            recommendation=recommendation,
            validation_method=validation_method,
            false_positive_likelihood=false_positive_likelihood,
            references=list(set(references)),  # Remove duplicates
            affected_component=vulnerability_data.get('affected_component', ''),
            proof_of_concept=vulnerability_data.get('proof_of_concept', '')
        )
    
    def _calculate_confidence_score(self, vuln_data: Dict[str, Any]) -> float:
        """Calculate confidence score based on multiple factors"""
        score = 0.5  # Base score
        
        # Factor 1: Detection method reliability
        detection_method = vuln_data.get('detection_method', 'pattern_match')
        method_scores = {
            'active_exploit': 0.9,
            'response_analysis': 0.8,
            'header_analysis': 0.7,
            'pattern_match': 0.6,
            'heuristic': 0.4
        }
        score += method_scores.get(detection_method, 0.3) * 0.3
        
        # Factor 2: Evidence quality
        evidence_quality = self._assess_evidence_quality(vuln_data)
        score += evidence_quality * 0.3
        
        # Factor 3: Cross-validation
        cross_validation = self._perform_cross_validation(vuln_data)
        score += cross_validation * 0.2
        
        # Factor 4: Historical accuracy for this vulnerability type
        historical_accuracy = self._get_historical_accuracy(vuln_data.get('category', ''))
        score += historical_accuracy * 0.2
        
        return min(1.0, max(0.0, score))
    
    def _assess_evidence_quality(self, vuln_data: Dict[str, Any]) -> float:
        """Assess the quality of evidence for the vulnerability"""
        quality_score = 0.0
        
        # Check for proof of concept
        if vuln_data.get('proof_of_concept'):
            quality_score += 0.3
        
        # Check for specific error messages or responses
        if vuln_data.get('error_response') or vuln_data.get('specific_response'):
            quality_score += 0.3
        
        # Check for multiple detection vectors
        detection_vectors = vuln_data.get('detection_vectors', [])
        if len(detection_vectors) > 1:
            quality_score += 0.2
        
        # Check for reproducibility
        if vuln_data.get('reproducible', False):
            quality_score += 0.2
        
        return min(1.0, quality_score)
    
    def _perform_cross_validation(self, vuln_data: Dict[str, Any]) -> float:
        """Perform cross-validation using multiple detection methods"""
        validation_score = 0.0
        
        # Simulate cross-validation (in real implementation, this would use multiple scanners)
        category = vuln_data.get('category', '')
        severity = vuln_data.get('severity', '')
        
        # Check consistency with known vulnerability patterns
        if self._check_pattern_consistency(vuln_data):
            validation_score += 0.4
        
        # Check against vulnerability databases
        if self._check_database_consistency(vuln_data):
            validation_score += 0.3
        
        # Check for common false positive indicators
        if not self._has_false_positive_indicators(vuln_data):
            validation_score += 0.3
        
        return min(1.0, validation_score)
    
    def _check_pattern_consistency(self, vuln_data: Dict[str, Any]) -> bool:
        """Check if vulnerability matches known patterns"""
        category = vuln_data.get('category', '')
        title = vuln_data.get('title', '').lower()
        
        # Define expected patterns for each category
        category_patterns = {
            'xss': ['script', 'javascript', 'cross-site', 'injection'],
            'sql_injection': ['sql', 'injection', 'database', 'query'],
            'csrf': ['csrf', 'cross-site request', 'token'],
            'ssl_issues': ['ssl', 'tls', 'certificate', 'encryption'],
            'information_disclosure': ['disclosure', 'exposure', 'leak', 'information']
        }
        
        expected_patterns = category_patterns.get(category, [])
        return any(pattern in title for pattern in expected_patterns)
    
    def _check_database_consistency(self, vuln_data: Dict[str, Any]) -> bool:
        """Check consistency with vulnerability databases"""
        cve_id = vuln_data.get('cve_id')
        if not cve_id:
            return False
        
        # Check against cached CVE data
        cached_cve = self.validation_cache.get(cve_id)
        if cached_cve:
            return self._compare_with_cve_data(vuln_data, cached_cve)
        
        return False
    
    def _has_false_positive_indicators(self, vuln_data: Dict[str, Any]) -> bool:
        """Check for common false positive indicators"""
        category = vuln_data.get('category', '')
        description = vuln_data.get('description', '').lower()
        
        false_positive_patterns = self.false_positive_patterns.get(category, [])
        return any(pattern.lower() in description for pattern in false_positive_patterns)
    
    def _get_historical_accuracy(self, category: str) -> float:
        """Get historical accuracy for vulnerability category"""
        # In a real implementation, this would query historical data
        historical_accuracies = {
            'xss': 0.75,
            'sql_injection': 0.80,
            'csrf': 0.70,
            'ssl_issues': 0.85,
            'information_disclosure': 0.65,
            'security_headers': 0.90,
            'default': 0.70
        }
        return historical_accuracies.get(category, historical_accuracies['default'])
    
    def _assess_false_positive_likelihood(self, vuln_data: Dict[str, Any]) -> float:
        """Assess likelihood of false positive"""
        likelihood = 0.0
        
        # Check for false positive indicators
        if self._has_false_positive_indicators(vuln_data):
            likelihood += 0.4
        
        # Check detection method reliability
        detection_method = vuln_data.get('detection_method', 'pattern_match')
        if detection_method in ['heuristic', 'pattern_match']:
            likelihood += 0.3
        
        # Check for ambiguous evidence
        if not vuln_data.get('proof_of_concept') and not vuln_data.get('specific_response'):
            likelihood += 0.2
        
        # Check for common false positive scenarios
        url = vuln_data.get('url', '')
        if any(indicator in url.lower() for indicator in ['localhost', '127.0.0.1', 'test', 'dev']):
            likelihood += 0.1
        
        return min(1.0, likelihood)
    
    def _validate_against_nvd(self, cve_id: str) -> Optional[Dict[str, Any]]:
        """Validate vulnerability against NVD database"""
        try:
            # Check cache first
            if cve_id in self.validation_cache:
                return self.validation_cache[cve_id]
            
            # Query NVD API
            url = f"{self.nvd_api_base}?cveId={cve_id}"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                vulnerabilities = data.get('vulnerabilities', [])
                
                if vulnerabilities:
                    cve_data = vulnerabilities[0].get('cve', {})
                    
                    # Extract relevant information
                    validation_data = {
                        'cve_id': cve_id,
                        'description': self._extract_cve_description(cve_data),
                        'severity': self._extract_cve_severity(cve_data),
                        'references': self._extract_cve_references(cve_data),
                        'published_date': cve_data.get('published'),
                        'modified_date': cve_data.get('lastModified')
                    }
                    
                    # Cache the result
                    self.validation_cache[cve_id] = validation_data
                    return validation_data
            
        except Exception as e:
            logger.error(f"Error validating CVE {cve_id}: {str(e)}")
        
        return None
    
    def _extract_cve_description(self, cve_data: Dict[str, Any]) -> str:
        """Extract description from CVE data"""
        descriptions = cve_data.get('descriptions', [])
        for desc in descriptions:
            if desc.get('lang') == 'en':
                return desc.get('value', '')
        return ''
    
    def _extract_cve_severity(self, cve_data: Dict[str, Any]) -> str:
        """Extract severity from CVE data"""
        metrics = cve_data.get('metrics', {})
        
        # Try CVSS v3.1 first
        cvss_v31 = metrics.get('cvssMetricV31', [])
        if cvss_v31:
            base_severity = cvss_v31[0].get('cvssData', {}).get('baseSeverity', '').lower()
            if base_severity:
                return base_severity
        
        # Try CVSS v3.0
        cvss_v30 = metrics.get('cvssMetricV30', [])
        if cvss_v30:
            base_severity = cvss_v30[0].get('cvssData', {}).get('baseSeverity', '').lower()
            if base_severity:
                return base_severity
        
        # Try CVSS v2
        cvss_v2 = metrics.get('cvssMetricV2', [])
        if cvss_v2:
            base_score = cvss_v2[0].get('cvssData', {}).get('baseScore', 0)
            if base_score >= 7.0:
                return 'high'
            elif base_score >= 4.0:
                return 'medium'
            else:
                return 'low'
        
        return 'unknown'
    
    def _extract_cve_references(self, cve_data: Dict[str, Any]) -> List[str]:
        """Extract references from CVE data"""
        references = []
        ref_data = cve_data.get('references', [])
        
        for ref in ref_data:
            url = ref.get('url')
            if url:
                references.append(url)
        
        return references
    
    def _compare_with_cve_data(self, vuln_data: Dict[str, Any], cve_data: Dict[str, Any]) -> bool:
        """Compare vulnerability data with CVE data for consistency"""
        # Compare severity
        detected_severity = vuln_data.get('severity', '').lower()
        cve_severity = cve_data.get('severity', '').lower()
        
        severity_mapping = {
            'critical': ['critical'],
            'high': ['high', 'critical'],
            'medium': ['medium', 'high'],
            'low': ['low', 'medium'],
            'info': ['low', 'info']
        }
        
        expected_severities = severity_mapping.get(detected_severity, [])
        if cve_severity not in expected_severities:
            return False
        
        # Compare descriptions for similarity
        detected_desc = vuln_data.get('description', '').lower()
        cve_desc = cve_data.get('description', '').lower()
        
        # Simple similarity check (in real implementation, use more sophisticated NLP)
        common_words = set(detected_desc.split()) & set(cve_desc.split())
        similarity = len(common_words) / max(len(detected_desc.split()), len(cve_desc.split()), 1)
        
        return similarity > 0.3  # 30% similarity threshold
    
    def _determine_validation_method(self, vuln_data: Dict[str, Any], cve_validation: Optional[Dict[str, Any]]) -> str:
        """Determine the validation method used"""
        methods = []
        
        if cve_validation:
            methods.append('nvd_validation')
        
        if vuln_data.get('proof_of_concept'):
            methods.append('proof_of_concept')
        
        if vuln_data.get('cross_validated'):
            methods.append('cross_validation')
        
        if vuln_data.get('manual_verification'):
            methods.append('manual_verification')
        
        if not methods:
            methods.append('pattern_matching')
        
        return ', '.join(methods)
    
    def _generate_enhanced_recommendation(self, vuln_data: Dict[str, Any], confidence_score: float) -> str:
        """Generate enhanced recommendation based on confidence score"""
        base_recommendation = vuln_data.get('recommendation', '')
        
        if confidence_score >= 0.9:
            prefix = "HIGH CONFIDENCE: "
        elif confidence_score >= 0.7:
            prefix = "MEDIUM CONFIDENCE: "
        elif confidence_score >= 0.5:
            prefix = "LOW CONFIDENCE: "
        else:
            prefix = "REQUIRES MANUAL VERIFICATION: "
        
        # Add confidence-based guidance
        if confidence_score < 0.7:
            suffix = " Please manually verify this finding before taking action."
        else:
            suffix = " This finding has been validated and should be addressed promptly."
        
        return prefix + base_recommendation + suffix
    
    def filter_high_confidence_vulnerabilities(self, vulnerabilities: List[Dict[str, Any]], 
                                             min_confidence: float = 0.7) -> List[ValidatedVulnerability]:
        """Filter vulnerabilities by confidence score"""
        validated_vulns = []
        
        for vuln in vulnerabilities:
            validated_vuln = self.validate_vulnerability(vuln)
            
            if validated_vuln.confidence_score >= min_confidence:
                validated_vulns.append(validated_vuln)
        
        return validated_vulns
    
    def generate_validation_report(self, validated_vulnerabilities: List[ValidatedVulnerability]) -> Dict[str, Any]:
        """Generate comprehensive validation report"""
        total_vulns = len(validated_vulnerabilities)
        
        if total_vulns == 0:
            return {
                'total_vulnerabilities': 0,
                'validation_summary': 'No vulnerabilities detected',
                'confidence_distribution': {},
                'false_positive_analysis': {}
            }
        
        # Calculate confidence distribution
        confidence_ranges = {
            'high_confidence': len([v for v in validated_vulnerabilities if v.confidence_score >= 0.8]),
            'medium_confidence': len([v for v in validated_vulnerabilities if 0.6 <= v.confidence_score < 0.8]),
            'low_confidence': len([v for v in validated_vulnerabilities if v.confidence_score < 0.6])
        }
        
        # Calculate false positive analysis
        avg_false_positive_likelihood = sum(v.false_positive_likelihood for v in validated_vulnerabilities) / total_vulns
        
        # Severity distribution
        severity_counts = {}
        for vuln in validated_vulnerabilities:
            severity = vuln.severity
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        return {
            'total_vulnerabilities': total_vulns,
            'confidence_distribution': confidence_ranges,
            'severity_distribution': severity_counts,
            'average_confidence_score': sum(v.confidence_score for v in validated_vulnerabilities) / total_vulns,
            'average_false_positive_likelihood': avg_false_positive_likelihood,
            'validation_methods_used': list(set(v.validation_method for v in validated_vulnerabilities)),
            'recommendations': self._generate_report_recommendations(validated_vulnerabilities)
        }
    
    def _generate_report_recommendations(self, validated_vulnerabilities: List[ValidatedVulnerability]) -> List[str]:
        """Generate recommendations based on validation results"""
        recommendations = []
        
        high_confidence_vulns = [v for v in validated_vulnerabilities if v.confidence_score >= 0.8]
        low_confidence_vulns = [v for v in validated_vulnerabilities if v.confidence_score < 0.6]
        
        if high_confidence_vulns:
            recommendations.append(f"Immediately address {len(high_confidence_vulns)} high-confidence vulnerabilities")
        
        if low_confidence_vulns:
            recommendations.append(f"Manually verify {len(low_confidence_vulns)} low-confidence findings")
        
        # Category-specific recommendations
        categories = set(v.category for v in validated_vulnerabilities)
        for category in categories:
            category_vulns = [v for v in validated_vulnerabilities if v.category == category]
            if len(category_vulns) > 2:
                recommendations.append(f"Focus on {category} vulnerabilities - {len(category_vulns)} instances found")
        
        return recommendations
